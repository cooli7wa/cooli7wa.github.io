<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.1" /><meta property="og:title" content="Neural Networks And Deep Learning Chap6" /><meta name="author" content="cooli7wa" /><meta property="og:locale" content="en" /><link rel="canonical" href="https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/" /><meta property="og:url" content="https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/" /><meta property="og:site_name" content="Cooli7wa" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2018-02-25T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Neural Networks And Deep Learning Chap6" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@cooli7wa" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"cooli7wa"},"dateModified":"2018-02-25T00:00:00+08:00","datePublished":"2018-02-25T00:00:00+08:00","headline":"Neural Networks And Deep Learning Chap6","mainEntityOfPage":{"@type":"WebPage","@id":"https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/"},"url":"https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/"}</script><title>Neural Networks And Deep Learning Chap6 | Cooli7wa</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cooli7wa"><meta name="application-name" content="Cooli7wa"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/images/cooli7wa.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Cooli7wa</a></div><div class="site-subtitle font-italic"></div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/github_username" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['cooli7wa67','163.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Neural Networks And Deep Learning Chap6</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Neural Networks And Deep Learning Chap6</h1><div class="post-meta text-muted"><div> By <em> <a href="https://cooli7wa67@163.com">cooli7wa</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2018-02-25 00:00:00 +0800" data-toggle="tooltip" data-placement="bottom" title="Sun, Feb 25, 2018, 12:00 AM +0800" >Feb 25, 2018</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1518 words"> <em>8 min</em> read</span></div></div></div><div class="post-content"> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><a href="http://neuralnetworksanddeeplearning.com/chap5.html">原文地址</a></p><h3 id="introducing-convolutional-networks">Introducing convolutional networks<a href="#introducing-convolutional-networks" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Local receptive fields</ul><p>局部采样</p><ul><li>shared weights</ul><p>分享权重</p><p>To see why this makes sense, suppose the weights and bias are such that the hidden neuron can pick out, say, a vertical edge in a particular local receptive field. That ability is also likely to be useful at other places in the image. And so it is useful to apply the same feature detector everywhere in the image.</p><p>分享权重为什么会有用？因为一般来说一套w和b，对应于获取图像的某一种特征，那么这种特征应该是全图像都需要的，所以对于图像的各个局部，都需要一样的权重。</p><p>The network structure I’ve described so far can detect just a single kind of localized feature. To do image recognition we’ll need more than one feature map. And so a complete convolutional layer consists of several different feature maps</p><p>一个正常的卷积层应该包含多个feature，也就是多组参数。</p><p>A big advantage of sharing weights and biases is that it greatly reduces the number of parameters involved in a convolutional network.</p><p>下面比较的就是卷积和全连接的参数数量，卷积可以有效缩减参数数量：</p><p>If we have 20 feature maps that’s a total of 20×26=520 parameters defining the convolutional layer.这是卷积的参数数量</p><p>That’s a total of 784×30 weights, plus an extra 30 biases, for a total of 23,550 parameters.这是全连接的参数数量</p><p>对比520和23550，全连接的参数数量大概是卷积的40倍。</p><ul><li>pooling<ul><li>max-pooling<li>L2 pooling</ul></ul><h3 id="convolutional-neural-networks-in-practice">Convolutional neural networks in practice<a href="#convolutional-neural-networks-in-practice" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>That’s a satisfying point of view, but gives rise to a second question. The output from the previous layer involves 20 separate feature maps, and so there are 20×12×12 inputs to the second convolutional-pooling layer. It’s as though we’ve got 20 separate images input to the convolutional-pooling layer, not a single image, as was the case for the first convolutional-pooling layer. How should neurons in the second convolutional-pooling layer respond to these multiple input images? In fact, we’ll allow each neuron in this layer to learn from all 20×5×5 input neurons in its local receptive field. More informally: the feature detectors in the second convolutional-pooling layer have access to all the features from the previous layer, but only within their particular local receptive field</p><p>这里每个神经元，要连接所有input的20个feature的5*5区域</p><p>However, across all my experiments I found that networks based on rectified linear units consistently outperformed networks based on sigmoid activation functions</p><p>relu要全面好过sigmoid</p><p>这些一步步提高了测试成绩</p><ul><li>增加额外的卷积和池化层<li>改用relu激活函数<li>扩展数据集<li>增加全连接层神经元数量，或者增加一个全连接层（效果不明显）<li>使用dropout<li>使用多个网络，共同决定分类（作者的意思是，这种方式其实是一种阻碍，且效果不明显）</ul><h3 id="why-we-only-applied-dropout-to-the-fully-connected-layers">Why we only applied dropout to the fully-connected layers<a href="#why-we-only-applied-dropout-to-the-fully-connected-layers" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>the convolutional layers have considerable inbuilt resistance to overfitting. The reason is that the shared weights mean that convolutional filters are forced to learn from across the entire image. This makes them less likely to pick up on local idiosyncracies in the training data. And so there is less need to apply other regularizers, such as dropout.</p><p>卷积已经有正则的效果了，因为卷积由于权值共享，实际上学习的是整个图像，这样过拟合的现象就比较不容易发生。</p><h3 id="why-are-we-able-to-train">Why are we able to train?<a href="#why-are-we-able-to-train" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>上章的最后的问题是，如何避免梯度消失和爆炸</p><p>这里的答案是，<strong>我们现在也没解决，只是多做了一些优化</strong></p><p>(1) Using convolutional layers greatly reduces the number of parameters in those layers, making the learning problem much easier;</p><p>(2) Using more powerful regularization techniques (notably dropout and convolutional layers) to reduce overfitting, which is otherwise more of a problem in more complex networks;</p><p>(3) Using rectified linear units instead of sigmoid neurons, to speed up training - empirically, often by a factor of 3-5;</p><p>(4) Using GPUs and being willing to train for a long period of time.</p><ul><li>making use of sufficiently large data sets (to help avoid overfitting);<li>using the right cost function (to avoid a learning slowdown);<li>using good weight initializations (also to avoid a learning slowdown, due to neuron saturation);<li>algorithmically expanding the training data.</ul><h3 id="recent-progress-in-image-recognition">Recent progress in image recognition<a href="#recent-progress-in-image-recognition" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>增加一些扰动，可能就无法识别，比如：</p><p><img data-src="/images/md/chap6_1.jpg" alt="" data-proofer-ignore></p><p>The existence of the adversarial negatives appears to be in contradiction with the network’s ability to achieve high generalization performance. Indeed, if the network can generalize well, how can it be confused by these adversarial negatives, which are indistinguishable from the regular examples? The explanation is that the set of adversarial negatives is of extremely low probability, and thus is never (or rarely) observed in the test set, yet it is dense (much like the rational numbers), and so it is found near virtually every test case.</p><p>这种扰动为什么正则没有用处？实际上，这种扰动在测试和学习集中，出现的几率非常低，所以没有学习到，而常规的正则解决不了这样问题，这种或许智能通过人为扩展数据集才行。</p><h3 id="other-approaches-to-deep-neural-nets">Other approaches to deep neural nets<a href="#other-approaches-to-deep-neural-nets" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Recurrent neural networks</ul><p>Indeed, a neuron’s activation might be determined in part by its own activation at an earlier time.</p><p>Or perhaps the activations of hidden and output neurons won’t be determined just by the current input to the network, but also by earlier inputs.</p><p>神经元本身会受到之前的激发状态的影响或者受到之前的输入的影响</p><p>they’re particularly useful in analysing data or processes that change over time. Such data and processes arise naturally in problems such as speech or natural language, for example.</p><p>用来识别有时间流逝的数据或者进程，比如谈话或自然语言。</p><ul><li>Long short-term memory units (LSTMs)</ul><p>One challenge affecting RNNs is that early models turned out to be very difficult to train, harder even than deep feedforward networks. The reason is the unstable gradient problem discussed in Chapter 5. Recall that the usual manifestation of this problem is that the gradient gets smaller and smaller as it is propagated back through layers. This makes learning in early layers extremely slow. The problem actually gets worse in RNNs, since gradients aren’t just propagated backward through layers, they’re propagated backward through time.</p><p>在RNN内，梯度不稳定的问题，更加明显，因为梯度不只是通过层来传播，还有时间。 LSTM的加入会对这个有所帮助</p><ul><li>Deep belief nets, generative models, and Boltzmann machines</ul><p>DBN</p><p>In this, a generative model is much like the human brain: not only can it read digits, it can also write them</p><p>A second reason DBNs are interesting is that they can do unsupervised and semi-supervised learning.</p><ul><li>reinforcement learning</ul><p>加强学习，比如学习如何打游戏，下面是作者推荐的两篇文章 这个我以后可能会用到</p><p>http://www.cs.toronto.edu/~vmnih/docs/dqn.pdf</p><p>https://www.nature.com/articles/nature14236</p><h3 id="on-the-future-of-neural-networks">On the future of neural networks<a href="#on-the-future-of-neural-networks" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Intention-driven user interfaces<li>Machine learning, data science, and the virtuous circle of innovation<li>The role of neural networks and deep learning</ul><h3 id="will-neural-networks-and-deep-learning-soon-lead-to-artificial-intelligence">Will neural networks and deep learning soon lead to artificial intelligence?<a href="#will-neural-networks-and-deep-learning-soon-lead-to-artificial-intelligence" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>it’s too early to say</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/study/'>study</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Neural Networks And Deep Learning Chap6 - Cooli7wa&url=https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Neural Networks And Deep Learning Chap6 - Cooli7wa&u=https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Neural Networks And Deep Learning Chap6 - Cooli7wa&url=https://cooli7wa.github.io/posts/Neural_Networks_And_Deep_Learning_Chap6/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Neural_Networks_And_Deep_Learning_Chap1/"><div class="card-body"> <em class="timeago small" date="2018-02-22 00:00:00 +0800" >Feb 22, 2018</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Neural Networks And Deep Learning Chap1</h3><div class="text-muted small"><p> 原文地址 perceptrons（感知器） 1950s-1960s by scientist Frank Rosenblatt 数学模型： 所有权重参数为w1,w2…，threshold threshold，Dropping the threshold means you’re more willing to go to the festival. 与权重b是同一种意...</p></div></div></a></div><div class="card"> <a href="/posts/Neural_Networks_And_Deep_Learning_Chap2/"><div class="card-body"> <em class="timeago small" date="2018-02-23 00:00:00 +0800" >Feb 23, 2018</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Neural Networks And Deep Learning Chap2</h3><div class="text-muted small"><p> 原文地址 Warm up: a fast matrix-based approach to computing the output from a neural network The two assumptions we need about the cost function 两个假设： \[C=\frac{1}{2n}\sum_x \left \| y(x)-a^{L...</p></div></div></a></div><div class="card"> <a href="/posts/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%BA%A4%E6%98%93%E4%BD%93%E5%88%9B%E5%BB%BA/"><div class="card-body"> <em class="timeago small" date="2019-01-04 00:00:00 +0800" >Jan 4, 2019</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>以太坊源码学习-交易体创建</h3><div class="text-muted small"><p> 这篇文章学习以太坊转账中交易生成流程。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // internal/ethapi/api.go // SendTransaction will create a transaction from the given arguments and // tries to sign it with th...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Neural_Networks_And_Deep_Learning_Chap5/" class="btn btn-outline-primary" prompt="Older"><p>Neural Networks And Deep Learning Chap5</p></a> <a href="/posts/Neural_Networks_And_Deep_Learning_Chap4/" class="btn btn-outline-primary" prompt="Newer"><p>Neural Networks And Deep Learning Chap4</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/cooli7wa">Cooli7wa</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
